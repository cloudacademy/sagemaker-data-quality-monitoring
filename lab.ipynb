{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Jupyter notebooks are divided into cells that can contain markdown or code that you can run interactively from the notebook interface. You can progress through the cells in the notebook by clicking the play button in the notebook tab's toolbar:\n",
    "\n",
    "![](assets/2024-09-09-09-50-34.png)\n",
    "\n",
    "Click the play button to advance to the next cell and continue on in the lab whenever you have completed a cell.\n",
    "\n",
    "After clicking the play button, the status in the left-hand side of the bottom status bar will change from **Idle** to **Busy**:\n",
    "\n",
    "![](assets/2024-09-09-09-50-00.png)\n",
    "\n",
    "Wait for the status to change back to **Idle** before proceeding to the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook overview\n",
    "\n",
    "This notebook guides you through the process of configuring an Amazon SageMaker Model Monitoring schedule for a pre-trained model.\n",
    "\n",
    "In this lab, an Amazon SageMaker endpoint with a pre-trained model has been deployed for you. The model has been trained on a synthetic dataset using the XGBoost algorithm.\n",
    "\n",
    "You will use the Python3 programming language to interact with the Amazon SageMaker SDK to configure a model monitoring schedule for the endpoint. You will also examine the data that the endpoint receives and the data that the endpoint returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring dependencies are installed\n",
    "\n",
    "To begin with, you will ensure that the correct dependency versions are installed. The following cell uses the Python package installer `pip` to install specific versions of the libraries used in this notebook.\n",
    "\n",
    "Ensuring that dependencies are using specific versions means that you can re-run the notebook over time without encountering issues due to changes in the libraries.\n",
    "\n",
    "Run the following cell to ensure that the dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "! pip install --upgrade pip\n",
    "!{sys.executable} -m pip install sagemaker==2.232.1 scikit-learn==1.5.2 pandas==2.2.3\n",
    "!{sys.executable} -m pip install -U boto3==1.35.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: You may see an errors and warnings about the `pip` dependency resolver. These are expected and can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the notebook session\n",
    "\n",
    "To use the Amazon SageMaker SDK, you need to set up the notebook session with the appropriate permissions. The following cell:\n",
    "\n",
    "- Imports the `boto3` and `sagemaker` libraries\n",
    "- Creates a SageMaker session\n",
    "- Defines the name of pre-created SageMaker endpoint\n",
    "- Retrieves the IAM role associated with the notebook instance\n",
    "- Retrieves the name of a bucket that was created for you during lab setup\n",
    "\n",
    "Run the following cell to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "endpoint_name = \"lab-sagemaker-endpoint\"\n",
    "\n",
    "bucket = next(\n",
    "    (\n",
    "        bucket[\"Name\"]\n",
    "        for bucket in boto3.client(\"s3\").list_buckets()[\"Buckets\"]\n",
    "        if bucket[\"Name\"].startswith(\"lab-sagemaker-\")\n",
    "    ),\n",
    "    None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the synthetic dataset\n",
    "\n",
    "The model that the Amazon SageMaker endpoint is using was trained on a synthetic dataset. The following code cell generates a sample of the synthetic data used and saves it to a CSV file.\n",
    "\n",
    "The synthetic data is structured for binary classification. In this case, it creates 20 samples, each with 10 features, where 8 are informative and 2 are redundant. There are 2 target classes, and the random_state=42 ensures that the generated data is reproducible.\n",
    "\n",
    "Binary classification has a wide variety of applications, including spam detection, fraud detection, and medical diagnosis.\n",
    "\n",
    "The sample dataset is converted to a pandas DataFrame before being saved to a CSV file.\n",
    "\n",
    "Run the following cell to generate the synthetic data and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "X_normal, y_normal = make_classification(\n",
    "    n_samples=20,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "df_normal = pd.DataFrame(X_normal, columns=[f\"feature_{i}\" for i in range(1, 11)])\n",
    "df_normal[\"target\"] = y_normal\n",
    "\n",
    "df_normal.to_csv(\"synthetic_normal_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to display the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending data to the endpoint\n",
    "\n",
    "To see how the model responds to normal data, you can send the synthetic data you have generated to the endpoint.\n",
    "\n",
    "The following cell removes the target column from the synthetic data, creates a client for the `sagemaker-runtime` service, and sends the data to the endpoint.\n",
    "\n",
    "Run the following cell to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = df_normal.drop(\"target\", axis=1).values\n",
    "\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "for row in inference_data:\n",
    "    payload = \",\".join(map(str, row))\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    "    )\n",
    "    result = response[\"Body\"].read()\n",
    "    print(float(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response, you will see the model's predictions for the synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating anomalous data\n",
    "\n",
    "To see how the model responds to anomalous data, you can generate some data that is different from the synthetic data you have generated.\n",
    "\n",
    "The following cell generates twenty samples of synthetic data with a different distribution from the original synthetic data. The number of features is the same (10), but number of informative and redundant features is different. The data is then converted to a pandas DataFrame and saved to a CSV file.\n",
    "\n",
    "This changed dataset is intended to represent drift in the data distribution that the model was trained on. This can occur in non-laboratory settings due to changes in the data source or changes in the data collection process. Drift can lead to a decrease in model performance.\n",
    "\n",
    "Run the following cell to generate anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "X_drifted, y_drifted = make_classification(\n",
    "    n_features=10,\n",
    "    n_samples=20,\n",
    "    n_informative=4,\n",
    "    n_redundant=6,\n",
    "    n_classes=2,\n",
    "    random_state=99,\n",
    ")\n",
    "\n",
    "df_drifted = pd.DataFrame(X_normal, columns=[f\"feature_{i}\" for i in range(1, 11)])\n",
    "df_drifted[\"target\"] = y_normal\n",
    "\n",
    "df_drifted.to_csv(\"synthetic_drifted_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to view the anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drifted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing data quality \n",
    "\n",
    "As well as drift, data quality issues such as missing values, or unexpected outliers can also affect model performance. The following cell introduces some data quality issues to the anomalous data.\n",
    "\n",
    "One value is set to the constant `nan` representing a missing value, and another value is set to a large number, representing an unexpected outlier.\n",
    "\n",
    "Run the following cell to introduce data quality issues to the anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_drifted.loc[df_drifted.sample(frac=0.1).index, \"feature_1\"] = np.nan\n",
    "df_drifted.loc[df_drifted.sample(frac=0.1).index, \"feature_2\"] *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending anomalous data to the endpoint\n",
    "\n",
    "To see how the model responds to the anomalous data, you can send the anomalous data you have generated to the endpoint.\n",
    " \n",
    "Run the following cell to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = df_drifted.drop(\"target\", axis=1).values\n",
    "\n",
    "for row in inference_data:\n",
    "    payload = \",\".join(map(str, row))\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    "    )\n",
    "    result = response[\"Body\"].read()\n",
    "    print(float(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response, you will see the model's predictions for the anomalous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing to configure model monitoring\n",
    "\n",
    "To help you identify when a model is no longer performing, Amazon SageMaker provides model monitoring. Model monitoring allows you to set up a schedule to monitor the data that the model receives and the data that the model returns.\n",
    "\n",
    "The first step in configuring model monitoring is to enable data capture for the Amazon SageMaker endpoint you wish to monitor. Once enabled, data is captured as the endpoint receives requests and returns responses. The captured data is stored in Amazon S3.\n",
    "\n",
    "The second step in configuring model monitoring is to create a baseline. The baseline is a dataset that represents the expected distribution of the data that the model receives and the data that the model returns. Generating the baseline data requires capturing data and using an Amazon SageMaker processing job.\n",
    "\n",
    "Amazon SageMaker Model Monitor uses the baseline data when the model is no longer performing as expected.\n",
    "\n",
    "In this lab, for the sake of time and convenience, data capture has been enabled on the endpoint for you, and baseline data has been provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing data capture configuration on an endpoint\n",
    "\n",
    "The following cell uses the SageMaker SDK to retrieve the configuration of the endpoint. The `IPython.display` library is used to display the configuration in a human-readable format.\n",
    "\n",
    "The `CurrentSamplingPercentage` attribute is set to 100, meaning that all data is captured. And, a `DestinationS3Uri` attribute is set to the Amazon S3 URI where the captured data is stored.\n",
    "\n",
    "Run the following cell to see the configuration of the endpoint resource, and locate the `DataCaptureConfig` attribute to see the data capture configuration for the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import JSON\n",
    "\n",
    "response = boto3.client(\"sagemaker\").describe_endpoint(EndpointName=endpoint_name)\n",
    "JSON(response, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing the baseline data\n",
    "\n",
    "In this lab, a baseline for the model has been provided for you. The following cell creates variables containing Amazon S3 URIs for the baseline data.\n",
    "\n",
    "The baseline data consists of a statistics JSON file and a constraints JSON file. The statistics file defines the expected distribution of the data, and the constraints file defines the constraints that the data should adhere to.\n",
    "\n",
    "Run the following cell to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_statistics = f\"s3://{bucket}/baseline_output/statistics.json\"\n",
    "baseline_constraints = f\"s3://{bucket}/baseline_output/constraints.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the contents of the statistics and constraints files, you can run the following three cells.\n",
    "\n",
    "The first cell reads the files from the Amazon S3 bucket and the second and third cells display the contents of the statistics and constraints files using the JSON helper from the `IPython.display` library.\n",
    "\n",
    "Run the following cells to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "statistics_content = (\n",
    "    s3.Object(bucket, \"baseline_output/statistics.json\")\n",
    "    .get()[\"Body\"]\n",
    "    .read()\n",
    "    .decode(\"utf-8\")\n",
    ")\n",
    "constraints_content = (\n",
    "    s3.Object(bucket, \"baseline_output/constraints.json\")\n",
    "    .get()[\"Body\"]\n",
    "    .read()\n",
    "    .decode(\"utf-8\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(json.loads(statistics_content), expanded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(json.loads(constraints_content), expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring model monitoring\n",
    "\n",
    "The final step in configuring model monitoring is to create a monitoring schedule. The monitoring schedule defines the frequency at which the model is monitored and the Amazon S3 URI where the monitoring results are stored.\n",
    "\n",
    "This is a two step process. First you create a `DefaultModelMonitor` object, which defines the instance type of the processing job that will be used to monitor the model.\n",
    "\n",
    "Then, using the model monitor object, you create a monitoring schedule resource. The configuration of this resource specifies the following:\n",
    "\n",
    "- Where the monitoring output will be stored\n",
    "- S3 URIs of the baseline data\n",
    "- The name of the endpoint to monitor\n",
    "- A cron expression denoting how frequently the monitoring job should run\n",
    "\n",
    "Run the following cell to configure model monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "monitor.create_monitoring_schedule(\n",
    "    endpoint_input=endpoint_name,\n",
    "    output_s3_uri=f\"s3://{bucket}/monitoring_output\",\n",
    "    statistics=baseline_statistics,\n",
    "    constraints=baseline_constraints,\n",
    "    schedule_cron_expression=CronExpressionGenerator.daily(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the lab step to complete the lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
