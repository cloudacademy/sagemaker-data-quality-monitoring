{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the notebook session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()  # Use the appropriate IAM role\n",
    "endpoint_name = \"lab-sagemaker-endpoint\"\n",
    "\n",
    "bucket_name = next(\n",
    "    (\n",
    "        bucket[\"Name\"]\n",
    "        for bucket in boto3.client(\"s3\").list_buckets()[\"Buckets\"]\n",
    "        if bucket[\"Name\"].startswith(\"lab-sagemaker-\")\n",
    "    ),\n",
    "    None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending Normal Data to the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate new synthetic data that matches the original training distribution\n",
    "X_normal, y_normal = make_classification(\n",
    "    n_samples=20,       # Number of samples to send to the endpoint\n",
    "    n_features=10,       # Number of features (same as training data)\n",
    "    n_informative=8,     # Number of informative features (same as training data)\n",
    "    n_redundant=2,       # Number of redundant features (same as training data)\n",
    "    n_classes=2,         # Binary classification\n",
    "    random_state=42      # For reproducibility (same seed as training data)\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame for easier handling\n",
    "df_normal = pd.DataFrame(X_normal, columns=[f'feature_{i}' for i in range(1, 11)])\n",
    "df_normal['target'] = y_normal  # Add target column if necessary, though the model only needs features\n",
    "\n",
    "# You can save this data to a CSV if required\n",
    "df_normal.to_csv('synthetic_normal_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df_normal.drop(columns=['target']).values.tolist()  # Convert to a 2D list for CSV input\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker.Session(),  # Initialize SageMaker session\n",
    "    serializer=CSVSerializer(),  # Specifies input format as CSV\n",
    "    deserializer=JSOeDeserializer()  # Specifies output format as JSON\n",
    ")\n",
    "\n",
    "# Convert each row of the dataset to the CSV format and send it to the endpoint\n",
    "for row in input_data:\n",
    "    response = predictor.predict(row)  # Send each row for prediction\n",
    "    print(response)  # Optionally, print the response for each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline processing job typically takes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "s3_key = \"data-capture\"\n",
    "\n",
    "baseline_job = monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket_name}/{s3_key}',\n",
    "    dataset_format={'csv': {'header': True}},\n",
    "    output_s3_uri=f's3://{bucket_name}/baseline_output',\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "endpoint_name = 'lab-sagemaker-endpoint'\n",
    "\n",
    "monitor.create_monitoring_schedule(\n",
    "    endpoint_input=endpoint_name,\n",
    "    output_s3_uri=f's3://{bucket_name}/monitoring_output',\n",
    "    statistics=baseline_job.baseline_statistics(),\n",
    "    constraints=baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Data Drift and Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate new synthetic data with drift\n",
    "X_drifted, y_drifted = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=4,    # Reduced informative features\n",
    "    n_redundant=6,      # Increased redundant features\n",
    "    n_classes=2,\n",
    "    random_state=99     # Different seed for variation\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df_drifted = pd.DataFrame(X_drifted, columns=feature_names)\n",
    "df_drifted['target'] = y_drifted\n",
    "\n",
    "# Save to CSV\n",
    "df_drifted.to_csv('synthetic_drifted_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Introduce missing values\n",
    "df_drifted.loc[df_drifted.sample(frac=0.1).index, 'feature_1'] = np.nan\n",
    "\n",
    "# Introduce outliers\n",
    "df_drifted.loc[df_drifted.sample(frac=0.05).index, 'feature_2'] *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending new data to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Prepare data for inference\n",
    "inference_data = df_drifted.drop('target', axis=1).values\n",
    "\n",
    "# Send data to endpoint\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "for row in inference_data:\n",
    "    payload = ','.join(map(str, row))\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=predictor.endpoint_name,\n",
    "        ContentType='text/csv',\n",
    "        Body=payload\n",
    "    )\n",
    "    result = response['Body'].read()\n",
    "    # Optionally, process the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predictor object\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker.Session(),  # Initialize SageMaker session\n",
    "    serializer=CSVSerializer(),  # Specifies input format as CSV\n",
    "    deserializer=JSONDeserializer()  # Specifies output format as JSON\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
